import cloudscraper
from bs4 import BeautifulSoup
from .utils import classify_subcategory, classify_category


def fetch_allcon_competitions():
    url = "https://www.all-con.co.kr/list/contest/1/1?sortname=cl_order&sortorder=asc"
    headers = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/114.0.0.0 Safari/537.36"
    ),
    "Referer": "https://www.all-con.co.kr/",
    "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
    }
    scraper = cloudscraper.create_scraper()
    resp = scraper.get(url)
    resp.encoding = "utf-8"
    soup = BeautifulSoup(resp.text, "html.parser")

    items = soup.select("div.card-contest-list div.contest-item")
    print("ğŸ”¥ crawler.py ì§„ì§œ ìˆ˜ì •ëœ ë²„ì „ ì‹¤í–‰ë¨")

    print("ğŸ” ì„ íƒì ì°¾ì€ í•­ëª© ìˆ˜:", len(items))
    print("ğŸ” í˜ì´ì§€ HTML (ì• 2000ì):\n", soup.prettify()[:2000])
    print("ğŸ§ª ì‘ë‹µ ìƒíƒœ ì½”ë“œ:", resp.status_code)
    print("ğŸ§ª ì‘ë‹µ ë³¸ë¬¸ ì¼ë¶€:", resp.text[:100])


    contests = []
    for item in items:
        title_tag = item.select_one("strong.tit")
        category_tag = item.select_one("span.cate")
        date_tag = item.select_one("span.date")
        link_tag = item.select_one("a")

        if not (title_tag and category_tag and date_tag and link_tag):
            continue

        title_text = title_tag.get_text(strip=True)
        link = link_tag["href"]
        detail_info = fetch_competition_detail_page(link)

        contests.append({
            "title": title_text,
            "subcategory": classify_subcategory(title_text),
            "category": classify_category(title_text),
            "deadline": None,
            "link": link,
            "description": detail_info.get("description", ""),
            "image_url": detail_info.get("image_url", ""),
        })
        print(f"âœ… ëˆ„ì  ê³µëª¨ì „ ìˆ˜: {len(contests)}")

    return contests

def fetch_competition_detail_page(detail_url):
    """
    Allcon ìƒì„¸ í˜ì´ì§€(ì˜ˆ: /view/contest/520261)ì—ì„œ
    1) contest_field í…Œì´ë¸”(ì£¼ìµœ/ì£¼ê´€/ì ‘ìˆ˜ê¸°ê°„/ë¶„ì•¼/ì‘ëª¨ëŒ€ìƒ/í˜œíƒ)ì„ ì¬ì¡°ë¦½í•˜ì—¬ HTMLë¡œ ê°€ì ¸ì˜¤ê³ ,
    2) ë³¸ë¬¸(ìœ íŠœë¸Œ í¬í•¨: ëª¨ì§‘ê°œìš”, ê¸°ê°„ ë° ì¼ì •, ì ‘ìˆ˜ë°©ë²•, í˜œíƒë‚´ì—­, ë¬¸ì˜ ë“±) ì „ì²´ë¥¼
       decode_contents()ë¡œ â€œHTML ê·¸ëŒ€ë¡œâ€ ê°€ì ¸ì™€ì„œ í•©ì¹œ ë’¤ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/113.0.0.0 Safari/537.36"
            )
        }

        # 1) detail_urlì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
        if detail_url.startswith("http"):
            full_url = detail_url
        else:
            full_url = "https://www.all-con.co.kr" + detail_url

        resp = requests.get(full_url, headers=headers, timeout=10)
        resp.encoding = "utf-8"
        soup = BeautifulSoup(resp.text, "html.parser")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) í¬ìŠ¤í„° ì´ë¯¸ì§€ ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        image_url = ""
        thumb = soup.select_one(".view_thumb img")
        if thumb and thumb.has_attr("src"):
            image_url = thumb["src"]
        else:
            poster_img = soup.select_one("img.poster-img")
            if poster_img and poster_img.has_attr("src"):
                image_url = poster_img["src"]
            else:
                any_poster = soup.find("img", src=lambda s: s and "poster" in s)
                if any_poster and any_poster.has_attr("src"):
                    image_url = any_poster["src"]

        if image_url.startswith("/"):
            image_url = "https://www.all-con.co.kr" + image_url

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) contest_field í…Œì´ë¸” ì¬ì¡°ë¦½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        clean_table_html = ""
        contest_field = soup.select_one("div.contest_field")
        if contest_field:
            tbl_tag = contest_field.find("table")
            if tbl_tag:
                rows = []
                for tr in tbl_tag.select("tbody tr"):
                    th = tr.select_one("th")
                    td = tr.select_one("td")
                    if th and td:
                        th_html = str(th)
                        td_html = str(td)
                        rows.append(f"<tr>{th_html}{td_html}</tr>")

                if rows:
                    caption_tag = tbl_tag.find("caption")
                    caption_html = str(caption_tag) if caption_tag else ""
                    new_table = (
                        f"<table>"
                        f"{caption_html}"
                        f"<tbody>{''.join(rows)}</tbody>"
                        f"</table>"
                    )
                    clean_table_html = f"<div class='detail-table'>{new_table}</div>"

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) ë³¸ë¬¸(ìœ íŠœë¸Œ + ëª¨ì§‘ê°œìš”~ë¬¸ì˜) ì „ì²´ HTML ê°€ì ¸ì˜¤ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        desc_html = ""
        # ì˜¬-ì½˜ ì‚¬ì´íŠ¸ ì‹¤ì œ HTMLì„ ì‚´í´ë³´ë‹ˆ, ë³¸ë¬¸(ìœ íŠœë¸Œ í¬í•¨)ì€ ëŒ€ê°œ ë‹¤ìŒ ë¸”ë¡ ì¤‘ í•˜ë‚˜ì— ë“¤ì–´ìˆìŠµë‹ˆë‹¤.
        desc_container = (
            soup.select_one("div.board_body_txt#contest_body")
            or soup.select_one("div.board_body_txt")
            or soup.select_one("div.board_body")
            or soup.select_one("div.contBox")
            or soup.select_one("div.view_contest")
            or soup.select_one("#contents")
            or soup.select_one("div.view_cont")
            or soup.select_one("section.contBox")
            or soup.select_one("div.tb_cont")
            or soup.select_one(".infoCont")
            or soup.select_one("article")
            or None
        )

        if desc_container:
            # decode_contents(): ë‚´ë¶€ì˜ ëª¨ë“  HTML(ìœ íŠœë¸Œ íƒœê·¸, <p>, <font>, &nbsp; í¬í•¨)ì„ í†µì§¸ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            desc_html = desc_container.decode_contents()
        else:
            # ìµœí›„ì˜ ìˆ˜ë‹¨: view_info ì•ˆì˜ <li> í•­ëª© HTMLì„ ê°€ì ¸ì˜¤ê¸°
            info_div = soup.select_one("div.view_info")
            if info_div:
                desc_html = info_div.decode_contents()

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) í…Œì´ë¸” + ë³¸ë¬¸ ì „ì²´ HTML í•©ì¹˜ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        full_html = ""
        if clean_table_html:
            full_html += clean_table_html + "<hr />"
        if desc_html:
            full_html += f"<div class='detail-body'>{desc_html}</div>"

        return {
            "image_url": image_url or "",
            "description": full_html or "",
        }

    except Exception as e:
        # ì¹˜ëª…ì  ì—ëŸ¬ê°€ ë‚œ ê²½ìš° ë¹ˆê°’ìœ¼ë¡œ ë¦¬í„´í•©ë‹ˆë‹¤.
        print(f"[ERROR] ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return {
            "image_url": "",
            "description": "",
        }
        
        