# team_match_training.py - íŒ€ ì í•©ë„ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ + ì…ë ¥ í•„í„°ë§ + ë²¡í„° ìƒì„±
import os  
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from .team_match_model import TeamMatchMLP

# ì—­í• /ê´€ì‹¬ì‚¬/ì–¸ì–´/êµ­ì  ë¦¬ìŠ¤íŠ¸
ALL_ROLES = [
    "ê¸°íš", "ë””ìì´ë„ˆ", "UX/UI ì„¤ê³„ì", "ì´¬ì˜/ê°ë…", "ì˜ìƒ í¸ì§‘ì", "ì‚¬ì§„ í›„ë³´ì •ì",
    "ë°œí‘œì/í”¼ì¹­", "ë¶„ì„/ë¦¬ì„œì²˜", "ìë£Œ ì¡°ì‚¬", "ë°ì´í„° ìˆ˜ì§‘/ë¶„ì„", "ë¬¸ì„œí™” ë‹´ë‹¹ì",
    "ë¸Œëœë”©/ë§ˆì¼€íŒ…", "í†µì—­/ì–¸ì–´", "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì", "ë°±ì—”ë“œ ê°œë°œì", "AI/ë°ì´í„° ê°œë°œì",
    "ìŒí–¥/ìŒì•… ë‹´ë‹¹ì", "ê²Œì´ë¨¸/í”Œë ˆì´ì–´", "ì—°ì¶œ/ë¬´ëŒ€ê¸°íšì"
]

ALL_INTERESTS = [
    "ì°½ì—…", "ì•„ì´ë””ì–´", "ìŠ¬ë¡œê±´", "ë„¤ì´ë°", "ë§ˆì¼€íŒ…",
    "ì‚¬ì§„", "ì˜ìƒ", "í¬ìŠ¤í„°", "ë¡œê³ ", "ìƒí’ˆ",
    "ìºë¦­í„°", "ê·¸ë¦¼", "ì›¹íˆ°", "ê´‘ê³ ", "ë„ì‹œê±´ì¶•",
    "ë…¼ë¬¸", "ìˆ˜ê¸°", "ì‹œ", "ì‹œë‚˜ë¦¬ì˜¤", "ê³µí•™",
    "ê³¼í•™", "ìŒì•…", "ëŒ„ìŠ¤", "eìŠ¤í¬ì¸ ", "ê¸°íƒ€"
]

ALL_LANGUAGES = ["Korean", "English", "Vietnamese", "Hindi", "Chinese", "Japanese", "French", "German", "Spanish", "Arabic"]
ALL_NATIONALITIES = ["Korea", "USA", "Vietnam", "India", "China", "Japan", "France", "Germany", "Mexico", "Brazil", "UK", "Canada", "Indonesia", "Russia", "Spain"]

# âœ… í•„ë“œ ê°œìˆ˜ ì œí•œ + ê²°ì¸¡ê°’ ëŒ€ì²´
def enforce_field_limits(user, max_items=3):
    def limit(field, allow_empty=False):
        values = user.get(field, [])
        values = values[:max_items]
        if not values and not allow_empty:
            values = ["ì—†ìŒ"]
        return values
    return {
        "roles": limit("roles"),
        "interests": limit("interests"),
        "languages": limit("languages"),
        "nationality": user.get("nationality", "Unknown")
    }

# âœ… ë²¡í„°í™” + ì •ê·œí™”
def create_advanced_feature_vector(user, team):
    def encode(values, vocab):
        return [1 if v in values else 0 for v in vocab]

    user_vec = (
        encode(user.get("roles", []), ALL_ROLES) +
        encode(user.get("interests", []), ALL_INTERESTS) +
        encode(user.get("languages", []), ALL_LANGUAGES) +
        [1 if user.get("nationality") == n else 0 for n in ALL_NATIONALITIES]
    )

    team_roles = sum([m.get("roles", []) for m in team], [])
    team_interests = sum([m.get("interests", []) for m in team], [])
    team_langs = sum([m.get("languages", []) for m in team], [])
    team_nats = [m.get("nationality") for m in team]

    team_vec = (
        encode(team_roles, ALL_ROLES) +
        encode(team_interests, ALL_INTERESTS) +
        encode(team_langs, ALL_LANGUAGES) +
        [team_nats.count(n) for n in ALL_NATIONALITIES]
    )

    role_overlap = len(set(user.get("roles", [])) & set(team_roles))
    interest_union = set(user.get("interests", [])).union(set(team_interests))
    interest_inter = set(user.get("interests", [])).intersection(set(team_interests))
    inter_jaccard = len(interest_inter) / len(interest_union) if interest_union else 0
    nat_diversity = len(set(team_nats))
    lang_overlap = len(set(user.get("languages", [])) & set(team_langs))

    vec = user_vec + team_vec + [role_overlap, inter_jaccard, nat_diversity, lang_overlap]
    
    if np.count_nonzero(vec) < 2:
        return None
    norm = np.linalg.norm(vec)
    return (np.array(vec) / norm).tolist() if norm > 0 else None

# âœ… í•™ìŠµìš© ë”ë¯¸ ìƒ˜í”Œ ìƒì„±
def create_advanced_dummy_samples(num_samples=1000):
    samples = []
    for _ in range(num_samples):
        user = enforce_field_limits({
            "roles": random.sample(ALL_ROLES, random.randint(0, 4)),
            "interests": random.sample(ALL_INTERESTS, random.randint(0, 4)),
            "languages": random.sample(ALL_LANGUAGES, random.randint(0, 4)),
            "nationality": random.choice(ALL_NATIONALITIES)
        })
        team = [enforce_field_limits({
            "roles": random.sample(ALL_ROLES, random.randint(0, 4)),
            "interests": random.sample(ALL_INTERESTS, random.randint(0, 4)),
            "languages": random.sample(ALL_LANGUAGES, random.randint(0, 4)),
            "nationality": random.choice(ALL_NATIONALITIES)
        }) for _ in range(random.randint(2, 4))]

        label = random.uniform(0.4, 0.9)
        vec = create_advanced_feature_vector(user, team)
        if vec:
            samples.append((vec, label))
    return samples

# âœ… ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ (ê²½ë¡œ í¬í•¨ ë²„ì „)
def train_model(samples, input_dim, save_name="team_match_advanced.pt"):
    class SampleDataset(Dataset):
        def __init__(self, data):
            self.data = data
        def __len__(self):
            return len(self.data)
        def __getitem__(self, idx):
            x, y = self.data[idx]
            return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)

    model = TeamMatchMLP(input_dim)
    loader = DataLoader(SampleDataset(samples), batch_size=64, shuffle=True)
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    loss_fn = nn.MSELoss()

    for epoch in range(5):
        total_loss = 0
        for x, y in loader:
            optimizer.zero_grad()
            pred = model(x)
            loss = loss_fn(pred, y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"[Epoch {epoch+1}] Loss: {total_loss / len(loader):.4f}")

    # ğŸ”¹ í˜„ì¬ íŒŒì¼ ê¸°ì¤€ ê²½ë¡œë¡œ ì €ì¥
    base_dir = os.path.dirname(os.path.abspath(__file__))
    save_path = os.path.join(base_dir, save_name)

    torch.save(model.state_dict(), save_path)
    print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ â†’ {save_path}")

if __name__ == "__main__":
    samples = create_advanced_dummy_samples(1000)
    print(f"ğŸ“Š ìœ íš¨ ìƒ˜í”Œ ìˆ˜: {len(samples)}")  # <- ì´ê±° ë°˜ë“œì‹œ í™•ì¸

    if not samples:
        print("âŒ ìœ íš¨í•œ í•™ìŠµ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµ ì¤‘ë‹¨.")
    else:
        input_dim = len(samples[0][0])
        train_model(samples, input_dim)
